{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "_btEngMNMiYM",
        "outputId": "685571f2-d779-4579-e10b-36a7ef065704"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b53567af-449d-434d-ab4f-39aad0ac2d39\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b53567af-449d-434d-ab4f-39aad0ac2d39\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ptbxl_database.csv to ptbxl_database.csv\n",
            "Saving scp_statements.csv to scp_statements.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "3nIQKCGMM7fM",
        "outputId": "7feb38a8-5e63-4691-fcb3-e7eeb1a1efb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3157f73a-41b5-4230-954f-2d59012e746d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3157f73a-41b5-4230-954f-2d59012e746d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 01000_lr.dat to 01000_lr.dat\n",
            "Saving 01000_lr.hea to 01000_lr.hea\n",
            "Saving 01001_lr.dat to 01001_lr.dat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a4\n",
        "\"\"\"\n",
        "modular_regression_with_random_search.py\n",
        "\n",
        "- Loads a regression dataset (diabetes by default)\n",
        "- Splits and scales data\n",
        "- Defines several regressors + hyperparameter search spaces\n",
        "- Tunes with RandomizedSearchCV (robust to errors)\n",
        "- Evaluates models on Train & Test with MSE, RMSE, MAE, R2, MAPE\n",
        "- Returns a pandas DataFrame summarising results\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from pprint import pprint\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# ---------------- Utility functions ----------------\n",
        "def load_dataset(kind=\"diabetes\"):\n",
        "    \"\"\"\n",
        "    Load a regression dataset. Default: sklearn's diabetes dataset.\n",
        "    Replace or modify to load your CSV.\n",
        "    Returns: X (ndarray), y (ndarray)\n",
        "    \"\"\"\n",
        "    if kind == \"diabetes\":\n",
        "        data = load_diabetes()\n",
        "        return data.data, data.target\n",
        "    else:\n",
        "        raise ValueError(\"Unknown dataset kind. Add loader code here.\")\n",
        "\n",
        "\n",
        "def split_data(X, y, test_size=0.2, random_state=42):\n",
        "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "\n",
        "def scale_data(X_train, X_test):\n",
        "    scaler = StandardScaler()\n",
        "    X_train_s = scaler.fit_transform(X_train)\n",
        "    X_test_s = scaler.transform(X_test)\n",
        "    return X_train_s, X_test_s, scaler\n",
        "\n",
        "\n",
        "def safe_mape(y_true, y_pred, eps=1e-8):\n",
        "    \"\"\"Compute MAPE safely (avoid division by zero). Returns percentage.\"\"\"\n",
        "    y_true = np.array(y_true, dtype=float)\n",
        "    y_pred = np.array(y_pred, dtype=float)\n",
        "    denom = np.where(np.abs(y_true) < eps, eps, y_true)\n",
        "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100.0\n",
        "\n",
        "\n",
        "def evaluate_regression(model, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"Compute MSE, RMSE, MAE, R2, MAPE for train and test splits.\"\"\"\n",
        "    results = {}\n",
        "    for label, (X, y) in [(\"Train\", (X_train, y_train)), (\"Test\", (X_test, y_test))]:\n",
        "        y_pred = model.predict(X)\n",
        "        mse = mean_squared_error(y, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(y, y_pred)\n",
        "        r2 = r2_score(y, y_pred)\n",
        "        mape = safe_mape(y, y_pred)\n",
        "        results[f\"MSE_{label}\"] = mse\n",
        "        results[f\"RMSE_{label}\"] = rmse\n",
        "        results[f\"MAE_{label}\"] = mae\n",
        "        results[f\"R2_{label}\"] = r2\n",
        "        results[f\"MAPE_{label}\"] = mape\n",
        "    return results\n",
        "\n",
        "\n",
        "def tune_hyperparameters(model, param_distributions, X_train, y_train,\n",
        "                         cv=3, n_iter=20, scoring=\"neg_mean_squared_error\", random_state=42):\n",
        "    \"\"\"\n",
        "    RandomizedSearchCV wrapper with safe fallback.\n",
        "    Returns (best_estimator, best_params) or (fitted_model, {}) on failure.\n",
        "    \"\"\"\n",
        "    if not param_distributions:  # nothing to tune\n",
        "        model.fit(X_train, y_train)\n",
        "        return model, {}\n",
        "\n",
        "    try:\n",
        "        rs = RandomizedSearchCV(\n",
        "            estimator=model,\n",
        "            param_distributions=param_distributions,\n",
        "            n_iter=n_iter,\n",
        "            cv=cv,\n",
        "            scoring=scoring,\n",
        "            random_state=random_state,\n",
        "            n_jobs=-1,\n",
        "            verbose=0,\n",
        "        )\n",
        "        rs.fit(X_train, y_train)\n",
        "        best = rs.best_estimator_\n",
        "        best_params = rs.best_params_\n",
        "        return best, best_params\n",
        "    except Exception as e:\n",
        "        print(f\"[Warning] RandomizedSearchCV failed for {model.__class__.__name__}: {e}\")\n",
        "        print(\"Falling back to model.fit() with default params.\")\n",
        "        try:\n",
        "            model.fit(X_train, y_train)\n",
        "            return model, {}\n",
        "        except Exception as e2:\n",
        "            raise RuntimeError(f\"Model fit also failed: {e2}\")\n",
        "\n",
        "\n",
        "# ---------------- Models & hyperparameter spaces ----------------\n",
        "def get_regressors_and_spaces(include_xgboost_if_available=True, include_catboost_if_available=True):\n",
        "    \"\"\"\n",
        "    Returns dict: {name: (estimator_instance, param_distributions_dict)}\n",
        "    If xgboost/catboost are installed, they will be added automatically.\n",
        "    \"\"\"\n",
        "    models = {\n",
        "        \"LinearRegression\": (LinearRegression(), {}),\n",
        "\n",
        "        \"DecisionTree\": (\n",
        "            DecisionTreeRegressor(random_state=42),\n",
        "            {\n",
        "                \"max_depth\": randint(1, 20),\n",
        "                \"min_samples_split\": randint(2, 20),\n",
        "                \"min_samples_leaf\": randint(1, 20)\n",
        "            }\n",
        "        ),\n",
        "\n",
        "        \"RandomForest\": (\n",
        "            RandomForestRegressor(random_state=42),\n",
        "            {\n",
        "                \"n_estimators\": randint(50, 200),\n",
        "                \"max_depth\": randint(3, 25),\n",
        "                \"min_samples_split\": randint(2, 20)\n",
        "            }\n",
        "        ),\n",
        "\n",
        "        \"SVR\": (\n",
        "            SVR(),\n",
        "            {\n",
        "                \"C\": uniform(loc=0.1, scale=100),\n",
        "                \"epsilon\": uniform(loc=0.001, scale=1),\n",
        "                \"kernel\": [\"rbf\", \"linear\", \"poly\"]\n",
        "            }\n",
        "        ),\n",
        "\n",
        "        \"KNN\": (\n",
        "            KNeighborsRegressor(),\n",
        "            {\n",
        "                \"n_neighbors\": randint(1, 30),\n",
        "                \"weights\": [\"uniform\", \"distance\"],\n",
        "                \"p\": [1, 2]\n",
        "            }\n",
        "        ),\n",
        "\n",
        "        \"MLP\": (\n",
        "            MLPRegressor(max_iter=1000, random_state=42),\n",
        "            {\n",
        "                \"hidden_layer_sizes\": [(50,), (100,), (100, 50)],\n",
        "                \"activation\": [\"relu\", \"tanh\"],\n",
        "                \"alpha\": uniform(loc=1e-6, scale=1e-2),\n",
        "                \"learning_rate_init\": uniform(loc=1e-4, scale=1e-1)\n",
        "            }\n",
        "        ),\n",
        "\n",
        "        \"AdaBoost\": (\n",
        "            AdaBoostRegressor(random_state=42),\n",
        "            {\n",
        "                \"n_estimators\": randint(50, 200),\n",
        "                \"learning_rate\": uniform(loc=0.01, scale=1.0)\n",
        "            }\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    # Optionally add XGBoost if installed\n",
        "    if include_xgboost_if_available:\n",
        "        try:\n",
        "            from xgboost import XGBRegressor\n",
        "            models[\"XGBoost\"] = (\n",
        "                XGBRegressor(random_state=42, verbosity=0),\n",
        "                {\n",
        "                    \"n_estimators\": randint(50, 200),\n",
        "                    \"max_depth\": randint(2, 10),\n",
        "                    \"learning_rate\": uniform(loc=0.01, scale=0.3)\n",
        "                }\n",
        "            )\n",
        "            print(\"[Info] XGBoost found and included.\")\n",
        "        except Exception:\n",
        "            print(\"[Info] xgboost not installed — skipping XGBoost.\")\n",
        "\n",
        "    # Optionally add CatBoost if installed\n",
        "    if include_catboost_if_available:\n",
        "        try:\n",
        "            from catboost import CatBoostRegressor\n",
        "            models[\"CatBoost\"] = (\n",
        "                CatBoostRegressor(random_state=42, verbose=0),\n",
        "                {\n",
        "                    \"iterations\": randint(50, 200),\n",
        "                    \"depth\": randint(2, 10),\n",
        "                    \"learning_rate\": uniform(loc=0.01, scale=0.3)\n",
        "                }\n",
        "            )\n",
        "            print(\"[Info] CatBoost found and included.\")\n",
        "        except Exception:\n",
        "            print(\"[Info] catboost not installed — skipping CatBoost.\")\n",
        "\n",
        "    return models\n",
        "\n",
        "\n",
        "# ---------------- Orchestration: run all models ----------------\n",
        "def run_all_regressors(X, y,\n",
        "                       test_size=0.2, random_state=42,\n",
        "                       cv=3, n_iter=20,\n",
        "                       include_xgboost=True, include_catboost=True):\n",
        "    \"\"\"\n",
        "    Main runner. Returns results dataframe.\n",
        "    \"\"\"\n",
        "    # Split\n",
        "    X_train, X_test, y_train, y_test = split_data(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Scale (recommended for e.g., SVR, MLP, KNN)\n",
        "    X_train_s, X_test_s, scaler = scale_data(X_train, X_test)\n",
        "\n",
        "    # Get models\n",
        "    models_and_spaces = get_regressors_and_spaces(include_xgboost_if_available=include_xgboost,\n",
        "                                                  include_catboost_if_available=include_catboost)\n",
        "\n",
        "    results = []\n",
        "    for name, (estimator, space) in models_and_spaces.items():\n",
        "        print(f\"\\n--- Running: {name} ---\")\n",
        "        # Tune or fit\n",
        "        try:\n",
        "            best_model, best_params = tune_hyperparameters(\n",
        "                estimator, space, X_train_s, y_train, cv=cv, n_iter=n_iter, scoring=\"neg_mean_squared_error\", random_state=random_state\n",
        "            )\n",
        "            if best_params:\n",
        "                print(\"Best params:\", best_params)\n",
        "        except RuntimeError as e:\n",
        "            print(f\"[Error] Skipping {name} due to fit failure: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Evaluate\n",
        "        metrics = evaluate_regression(best_model, X_train_s, y_train, X_test_s, y_test)\n",
        "        metrics[\"Model\"] = name\n",
        "        # store params for record\n",
        "        metrics[\"BestParams\"] = (best_params if best_params else {})\n",
        "        results.append(metrics)\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # reorder columns for readability\n",
        "    cols_order = [\"Model\", \"BestParams\",\n",
        "                  \"MSE_Train\", \"RMSE_Train\", \"MAE_Train\", \"R2_Train\", \"MAPE_Train\",\n",
        "                  \"MSE_Test\", \"RMSE_Test\", \"MAE_Test\", \"R2_Test\", \"MAPE_Test\"]\n",
        "    results_df = results_df[[c for c in cols_order if c in results_df.columns]]\n",
        "\n",
        "    # sort by RMSE_Test ascending (lower is better)\n",
        "    if \"RMSE_Test\" in results_df.columns:\n",
        "        results_df = results_df.sort_values(\"RMSE_Test\").reset_index(drop=True)\n",
        "\n",
        "    return results_df, scaler\n",
        "\n",
        "\n",
        "# ---------------- Demo main ----------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    X, y = load_dataset(\"diabetes\")  # replace with your loader if needed\n",
        "\n",
        "    # Run\n",
        "    results_df, scaler = run_all_regressors(X, y, test_size=0.2, random_state=42, cv=3, n_iter=25)\n",
        "\n",
        "    # Show full table\n",
        "    pd.set_option('display.max_colwidth', 200)\n",
        "    print(\"\\n=== Final Results (sorted by RMSE_Test) ===\")\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    # Optionally save to CSV\n",
        "    results_df.to_csv(\"regression_model_results.csv\", index=False)\n",
        "    print(\"\\nSaved results to regression_model_results.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omxBPMXJYHTb",
        "outputId": "38a04707-df9f-4ceb-c952-32dec13ca059"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] XGBoost found and included.\n",
            "[Info] catboost not installed — skipping CatBoost.\n",
            "\n",
            "--- Running: LinearRegression ---\n",
            "\n",
            "--- Running: DecisionTree ---\n",
            "Best params: {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 13}\n",
            "\n",
            "--- Running: RandomForest ---\n",
            "Best params: {'max_depth': 6, 'min_samples_split': 3, 'n_estimators': 183}\n",
            "\n",
            "--- Running: SVR ---\n",
            "Best params: {'C': np.float64(5.741157902710025), 'epsilon': np.float64(0.7229987722668247), 'kernel': 'linear'}\n",
            "\n",
            "--- Running: KNN ---\n",
            "Best params: {'n_neighbors': 15, 'p': 2, 'weights': 'uniform'}\n",
            "\n",
            "--- Running: MLP ---\n",
            "Best params: {'activation': 'relu', 'alpha': np.float64(0.0059695015794648705), 'hidden_layer_sizes': (100,), 'learning_rate_init': np.float64(0.015699452033620265)}\n",
            "\n",
            "--- Running: AdaBoost ---\n",
            "Best params: {'learning_rate': np.float64(0.8183973481164611), 'n_estimators': 58}\n",
            "\n",
            "--- Running: XGBoost ---\n",
            "Best params: {'learning_rate': np.float64(0.2140922615763339), 'max_depth': 2, 'n_estimators': 67}\n",
            "\n",
            "=== Final Results (sorted by RMSE_Test) ===\n",
            "           Model                                                                                                                       BestParams   MSE_Train  RMSE_Train  MAE_Train  R2_Train  MAPE_Train    MSE_Test  RMSE_Test  MAE_Test  R2_Test  MAPE_Test\n",
            "        AdaBoost                                                                        {'learning_rate': 0.8183973481164611, 'n_estimators': 58} 2314.054196   48.104617  41.726738  0.619173   39.125696 2838.603939  53.278550 43.802642 0.464228  42.448817\n",
            "LinearRegression                                                                                                                               {} 2868.549703   53.558843  43.483504  0.527919   38.919947 2900.193628  53.853446 42.794095 0.452603  37.499826\n",
            "    RandomForest                                                                    {'max_depth': 6, 'min_samples_split': 3, 'n_estimators': 183} 1203.237360   34.687712  28.830458  0.801982   26.181282 2917.678746  54.015542 43.650033 0.449303  39.587673\n",
            "         XGBoost                                                        {'learning_rate': 0.2140922615763339, 'max_depth': 2, 'n_estimators': 67} 1490.399441   38.605692  30.933381  0.754723   27.689460 2987.159514  54.654913 44.232236 0.436188  39.536136\n",
            "             SVR                                                      {'C': 5.741157902710025, 'epsilon': 0.7229987722668247, 'kernel': 'linear'} 2921.121654   54.047402  43.380683  0.519268   38.346718 2993.749436  54.715166 43.483624 0.434945  37.178863\n",
            "             KNN                                                                                {'n_neighbors': 15, 'p': 2, 'weights': 'uniform'} 3029.948530   55.044968  44.027951  0.501358   38.645548 3053.773383  55.260957 45.319850 0.423615  41.166880\n",
            "             MLP {'activation': 'relu', 'alpha': 0.0059695015794648705, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.015699452033620265} 1252.225657   35.386801  28.142597  0.793920   23.684379 3312.519829  57.554494 46.140167 0.374778  40.990956\n",
            "    DecisionTree                                                                 {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 13} 2935.039569   54.176005  43.682417  0.516977   38.737396 3552.701313  59.604541 48.096592 0.329445  43.069130\n",
            "\n",
            "Saved results to regression_model_results.csv\n"
          ]
        }
      ]
    }
  ]
}